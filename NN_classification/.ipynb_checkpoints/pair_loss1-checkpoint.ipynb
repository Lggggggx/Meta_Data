{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Net_3hiddens(\n",
      "  (input_bn): BatchNorm1d(418, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (first_hidden): Linear(in_features=418, out_features=200, bias=True)\n",
      "  (first_bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (second_hidden): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (second_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (third_hidden): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (third_bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=50, out_features=1, bias=True)\n",
      "), Net_3hiddens(\n",
      "  (input_bn): BatchNorm1d(418, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (first_hidden): Linear(in_features=418, out_features=200, bias=True)\n",
      "  (first_bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (second_hidden): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (second_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (third_hidden): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (third_bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=50, out_features=1, bias=True)\n",
      ")]\n",
      "[Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0005\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0.0005\n",
      ")]\n",
      "MyLoss()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "\n",
    "from MyNet import Net, MetaDataSet, MyLoss1, MyLoss, Net_3hiddens\n",
    "\n",
    "# hyper parameters\n",
    "BATCH_SIZE = 1000\n",
    "EPOCH_SIZE = 20\n",
    "\n",
    "LR = 1e-2\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY =  0.0005\n",
    "\n",
    "DATASET_SHUFFLE = False\n",
    "num_WORKERS = 3\n",
    "\n",
    "TASK = 'regression'\n",
    "\n",
    "XI = 0.0005\n",
    "\n",
    "\n",
    "save_path = './'\n",
    "metadata_dir = 'E:/metadata数据集/new_bigmetadata/australian/query_time/'\n",
    "\n",
    "# net = Net(n_feature=396, first_n_hidden=100, second_n_hidden=20, n_output=2)\n",
    "# net_bn = Net(n_feature=418, first_n_hidden=200, second_n_hidden=100, n_output=1, batch_normalization=True)\n",
    "# net_no_bn = Net(n_feature=418, first_n_hidden=200, second_n_hidden=100, n_output=1, batch_normalization=False)\n",
    "net3_bn = Net_3hiddens(n_feature=418, first_n_hidden=200, second_n_hidden=100, third_n_hidden=50, n_output=1, batch_normalization=True)\n",
    "net3_no_bn = Net_3hiddens(n_feature=418, first_n_hidden=200, second_n_hidden=100, third_n_hidden=50, n_output=1, batch_normalization=False)\n",
    "\n",
    "nets = [net3_bn, net3_no_bn]\n",
    "optimizers = [optim.Adam(net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY) for net in nets]\n",
    "criterion = MyLoss(XI)\n",
    "print(nets)\n",
    "print(optimizers)\n",
    "print(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Preparing the dataset....')\n",
    "# loader = MetaDataSet(metadata_dir, BATCH_SIZE, num_WORKERS, DATASET_SHUFFLE, TASK)\n",
    "# print(\"Dataset is ready!\")\n",
    "\n",
    "metadata1 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/2australian30_big_metadata30.npy')\n",
    "metadata2 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/4australian30_big_metadata30.npy')\n",
    "metadata3 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/10australian30_big_metadata30.npy')\n",
    "metadata4 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/20australian30_big_metadata30.npy')\n",
    "metadata5 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/30australian30_big_metadata30.npy')\n",
    "metadata6 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/48australian30_big_metadata30.npy')\n",
    "\n",
    "metadata = np.vstack((metadata1, metadata2, metadata3, metadata4, metadata5, metadata6))\n",
    "\n",
    "X = metadata[:, 0:418]\n",
    "y = metadata[:, 418]\n",
    "\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "X_tensor = X_tensor.float()\n",
    "y_tensor = y_tensor.float()\n",
    "\n",
    "troch_dataset = Data.TensorDataset(X_tensor, y_tensor)\n",
    "loader = Data.DataLoader(dataset=troch_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        num_workers=num_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tarining the NN\n",
    "for epoch in range(EPOCH_SIZE):\n",
    "    running_loss0 = 0.0\n",
    "    running_loss1 = 0.0\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "#         print('step',step)\n",
    "        min_b = int(BATCH_SIZE/2)\n",
    "        pari_y = batch_y[0:min_b] - batch_y[min_b:]\n",
    "#         if step % 20 == 19:    \n",
    "#             print('min pari_y',min(pari_y))\n",
    "#             print('max pari_y',max(pari_y))\n",
    "#             print('abs min pari_y',min(abs(pari_y)))\n",
    "#             print('abs max pari_y',max(abs(pari_y)))\n",
    "        for net, optimizer in zip(nets, optimizers):\n",
    "            optimizer.zero_grad()\n",
    "            output1 = net(batch_x[0:min_b,:])\n",
    "            output2 = net(batch_x[min_b:,:])\n",
    "            loss = criterion(output1, output2, pari_y)\n",
    "#             print('the dtype of loss ', loss.dtype)\n",
    "#             print('the shape of loss', loss.size())\n",
    "#             print('loss ', loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if net == nets[0]:\n",
    "                i = 0\n",
    "                # print statistics\n",
    "                running_loss0 += loss.item()\n",
    "                # print every 2000 mini-batches\n",
    "                if step % 20 == 19:    \n",
    "                    print('net',i,' [%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, step + 1, running_loss0 / 2000))\n",
    "                    running_loss0 = 0.0\n",
    "            else:\n",
    "                i = 1\n",
    "                # print statistics\n",
    "                running_loss1 += loss.item()\n",
    "                # print every 2000 mini-batches\n",
    "                if step % 20 == 19:    \n",
    "                    print('net',i,' [%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, step + 1, running_loss1 / 2000))\n",
    "                    running_loss1 = 0.0          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the parameters in NN\n",
    "torch.save({\n",
    "            'model_state_dict': nets[0].state_dict(),\n",
    "            'optimizer_state_dict': optimizers[0].state_dict(),\n",
    "            }, './pairloss_bn_net_parameters.pth')\n",
    "torch.save({\n",
    "            'model_state_dict': nets[1].state_dict(),\n",
    "            'optimizer_state_dict': optimizers[1].state_dict(),\n",
    "            }, './pairloss_nobn_net_parameters.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试数据集\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "\n",
    "metadata1 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/2australian30_big_metadata30.npy')\n",
    "metadata2 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/4australian30_big_metadata30.npy')\n",
    "metadata3 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/10australian30_big_metadata30.npy')\n",
    "metadata4 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/20australian30_big_metadata30.npy')\n",
    "metadata5 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/30australian30_big_metadata30.npy')\n",
    "metadata6 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/48australian30_big_metadata30.npy')\n",
    "\n",
    "metadata = np.vstack((metadata1, metadata2, metadata3, metadata4, metadata5, metadata6 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 普通回归测试\n",
    "net2 = nets[1]\n",
    "# X = metadata[:, 0:396]\n",
    "# y = metadata[:, 396]\n",
    "X = metadata[:, 0:418]\n",
    "y = metadata[:, 418]\n",
    "print(y.shape)\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "X_tensor = X_tensor.float()\n",
    "y_tensor = y_tensor.float()\n",
    "out = net2(X_tensor)\n",
    "print(out.size())\n",
    "pred = out.detach().numpy()\n",
    "print(pred.shape)\n",
    "print(pred[:,0].shape)\n",
    "# print(predict)\n",
    "# print(accuracy_score(y, predict))\n",
    "print(r2_score(y, pred[:,0]))\n",
    "y[np.where(y>0)[0]] = 1\n",
    "y[np.where(y<=0)[0]] = 0\n",
    "cperd = pred[:,0]\n",
    "cperd[np.where(cperd>0)[0]] = 1\n",
    "cperd[np.where(cperd<=0)[0]] = 0\n",
    "print(accuracy_score(y, cperd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81000,)\n",
      "0.5035802469135803\n"
     ]
    }
   ],
   "source": [
    "# ranking accuracy.\n",
    "net2 = nets[1]\n",
    "# print(net2)\n",
    "n_sample = metadata.shape[0]\n",
    "X = metadata[:, 0:418]\n",
    "X_tensor = torch.from_numpy(X)\n",
    "X_tensor = X_tensor.float()\n",
    "y = metadata[:, 418]\n",
    "\n",
    "# pair_X = [np.hstack((X[i,:],X[i+1,:])) for i in range(0, n_sample, 2)]\n",
    "pair_y = [(y[i]-y[i+1]) for i in range(0, n_sample, 2)]\n",
    "pair_y = np.array(pair_y)\n",
    "pair_y[np.where(pair_y>0)[0]] = 1\n",
    "pair_y[np.where(pair_y<=0)[0]] = 0\n",
    "out = net2(X_tensor)\n",
    "\n",
    "pred = out.detach().numpy()\n",
    "pred = pred[:,0]\n",
    "pred = [(pred[i]-pred[i+1]) for i in range(0, n_sample, 2)]\n",
    "pred = np.array(pred)\n",
    "pred[np.where(pred>0)[0]] = 1\n",
    "pred[np.where(pred<=0)[0]] = 0\n",
    "print(np.shape(pair_y))\n",
    "# pair_X_tensor = torch.from_numpy(pair_X)\n",
    "# pair_y_tensor = torch.from_numpy(pair_y)\n",
    "print(accuracy_score(pair_y, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pyroch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
