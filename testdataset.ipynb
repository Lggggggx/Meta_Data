{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********currently dataset is :  australian\n",
      "690\n",
      "(690,)\n",
      "[0.62846253 0.66865519 0.58896809 0.69506703 0.49274611 0.56590911\n",
      " 0.46389756 0.55435727 0.44142501 0.59911492 0.52173016 0.5661966\n",
      " 0.47571517 0.63824754 0.69052832 0.51705481 0.60944132 0.78228286\n",
      " 0.48438717 0.58875848 0.67604052 0.47897211 0.62999387 0.56916662\n",
      " 0.68958333 0.54965145 0.50144921 0.42563258 0.45038449 0.69326516\n",
      " 0.54363782 0.60022001 0.51409267 0.45366564 0.70576013 0.69672556\n",
      " 0.634687   0.54151999 0.53149004 0.54620052 0.64197186 0.59041471\n",
      " 0.571279   0.64427406 0.38776073 0.56077112 0.43109835 0.62492963\n",
      " 0.60749092 0.74745802 0.52597738 0.60910489 0.69587673 0.65853876\n",
      " 0.51164205 0.58693503 0.58364429 0.50994248 0.41125318 0.57282312\n",
      " 0.6310662  0.47881479 0.43762792 0.81535127 0.57103968 0.55442478\n",
      " 0.62702278 0.66402776 0.57259379 0.56711872 0.39408496 0.4519371\n",
      " 0.48217392 0.58976725 0.62388339 0.62488904 0.60807309 0.5263022\n",
      " 0.52431218 0.59638324 0.5515305  0.51310544 0.56491735 0.48372895\n",
      " 0.63240565 0.47822713 0.45010788 0.61645843 0.64193686 0.41599376\n",
      " 0.51994826 0.61180693 0.61153072 0.50894562 0.53447914 0.53447368\n",
      " 0.62158217 0.47951207 0.4323558  0.69275777 0.44610155 0.49527654\n",
      " 0.62458299 0.51808072 0.42905746 0.5013517  0.46083305 0.52415654\n",
      " 0.44605739 0.66911118 0.65697518 0.4838185  0.6672808  0.43575936\n",
      " 0.5076791  0.78434537 0.62626048 0.58131238 0.59741617 0.59422976\n",
      " 0.60540104 0.49499807 0.60057946 0.67044107 0.68901224 0.59612127\n",
      " 0.46179416 0.60394526 0.52694102 0.44410815 0.51250233 0.74719798\n",
      " 0.40720639 0.58236083 0.60273268 0.60796106 0.52998448 0.63350324\n",
      " 0.5648719  0.62991022 0.59412096 0.40800918 0.43190391 0.60115977\n",
      " 0.67536193 0.60541413 0.65942177 0.43811854 0.47094586 0.65376529\n",
      " 0.57755649 0.70976823 0.47879855 0.71891769 0.6065241  0.35303669\n",
      " 0.45629324 0.45772571 0.49521736 0.40429599 0.58289699 0.63545597\n",
      " 0.70679185 0.44444366 0.55788828 0.5550628  0.59938139 0.53843265\n",
      " 0.60426108 0.53045841 0.53167301 0.51606742 0.49345648 0.47971456\n",
      " 0.55747094 0.58122007 0.45883211 0.60787486 0.79322695 0.57966608\n",
      " 0.55164547 0.39194868 0.77163439 0.63389636 0.77629237 0.5793197\n",
      " 0.45872129 0.66673709 0.67926673 0.67581294 0.593918   0.49603079\n",
      " 0.54967854 0.54456525 0.48451291 0.47240021 0.48693269 0.53463238\n",
      " 0.48550624 0.63199613 0.6975104  0.5364519  0.7015185  0.67791507\n",
      " 0.55422564 0.65802837 0.5305947  0.60356716 0.57748234 0.5532812\n",
      " 0.62655513 0.41799202 0.51662631 0.52143407 0.5068616  0.48413859\n",
      " 0.61076914 0.56751504 0.45039874 0.45386271 0.589302   0.51277477\n",
      " 0.55410911 0.62289887 0.57944315 0.49238254 0.57016411 0.47332397\n",
      " 0.6573877  0.57694948 0.56672494 0.52458013 0.55313167 0.66536299\n",
      " 0.47603635 0.80138421 0.54788767 0.58191213 0.4757427  0.63874571\n",
      " 0.45313879 0.56768253 0.68020783 0.83721355 0.52556477 0.52451903\n",
      " 0.62028266 0.72435482 0.56552459 0.64397201 0.49489157 0.61073877\n",
      " 0.55255982 0.60226972 0.63916038 0.52271129 0.67168838 0.61882851\n",
      " 0.54667706 0.52301588 0.47980139 0.59521992 0.44184097 0.44293899\n",
      " 0.61597518 0.57627936 0.40974989 0.58348702 0.59218073 0.44632254\n",
      " 0.68352769 0.63936516 0.52639291 0.55278757 0.40041679 0.61404464\n",
      " 0.52157396 0.42191381 0.57377677 0.56965724 0.51184948 0.49036015\n",
      " 0.52240063 0.57120149 0.63705201 0.52147315 0.57113459 0.69090085\n",
      " 0.5748284  0.44530443 0.53766746 0.56056573 0.65570401 0.64209881\n",
      " 0.63599128 0.55889886 0.61032288 0.54362028 0.57681921 0.59422511\n",
      " 0.60665835 0.52604465 0.50423585 0.5407613  0.49517714 0.4163442\n",
      " 0.61827397 0.61603956 0.43944456 0.44456394 0.6108367  0.62208752\n",
      " 0.61474093 0.59081022 0.53583899 0.5223122  0.53370072 0.20536586\n",
      " 0.37613966 0.58342455 0.65330234 0.2436353  0.51342727 0.50280485\n",
      " 0.6860288  0.45301786 0.57747911 0.49049224 0.48035974 0.49089404\n",
      " 0.67600808 0.54880773 0.75233694 0.58069663 0.4633985  0.49237938\n",
      " 0.71693309 0.43632008 0.49493613 0.63944386 0.67324429 0.65611502\n",
      " 0.61068822 0.6349229  0.66833775 0.4202709  0.69628124 0.46797864\n",
      " 0.66838138 0.58749707 0.41311986 0.56354704 0.51945865 0.50642658\n",
      " 0.60424087 0.55608273 0.61520693 0.56456692 0.58154283 0.6421221\n",
      " 0.41375447 0.50449392 0.48026967 0.45786903 0.41690708 0.59088648\n",
      " 0.6361961  0.47090273 0.44621612 0.36654305 0.53502532 0.40753062\n",
      " 0.41159331 0.66052145 0.68795832 0.40107835 0.60386632 0.45340848\n",
      " 0.58802498 0.45567581 0.60307933 0.66398004 0.4242752  0.52675243\n",
      " 0.67105557 0.61180572 0.53243761 0.52293946 0.60072288 0.54726674\n",
      " 0.48419151 0.62637938 0.46619257 0.52331053 0.50759712 0.56752953\n",
      " 0.46249621 0.56495957 0.45403585 0.705588   0.47109925 0.73819307\n",
      " 0.54886245 0.43218792 0.4909122  0.43594753 0.47761054 0.45811999\n",
      " 0.65458935 0.60611211 0.63801268 0.63649671 0.52861338 0.49125778\n",
      " 0.71393651 0.55477752 0.58407472 0.6084652  0.62300449 0.50806601\n",
      " 0.59698383 0.63136548 0.65328944 0.55372928 0.62588436 0.73084807\n",
      " 0.60505165 0.48970706 0.63672943 0.52980586 0.59409671 0.58918302\n",
      " 0.74398825 0.69089498 0.674385   0.55459838 0.66109467 0.40715773\n",
      " 0.62773559 0.55689132 0.43065833 0.64597563 0.44514269 0.71614977\n",
      " 0.45147201 0.65393036 0.78900483 0.63413109 0.62709937 0.70180187\n",
      " 0.4786659  0.7031275  0.62277681 0.63631367 0.58666537 0.64432833\n",
      " 0.68808746 0.58962477 0.61688118 0.59206225 0.5339571  0.56364017\n",
      " 0.8206095  0.63858622 0.39747451 0.50929561 0.58287613 0.45177548\n",
      " 0.61509256 0.5352696  0.45074014 0.45774671 0.59657211 0.4853994\n",
      " 0.8120825  0.59227443 0.51874273 0.37067522 0.60597892 0.48630715\n",
      " 0.49470133 0.48522621 0.55738534 0.56885144 0.56090193 0.5048916\n",
      " 0.58252437 0.55574505 0.50118784 0.55144936 0.7247264  0.6536985\n",
      " 0.61478936 0.53626735 0.4512372  0.55873173 0.51285215 0.70850299\n",
      " 0.70659681 0.70068365 0.64469401 0.57892634 0.5336115  0.64470046\n",
      " 0.67557455 0.69279588 0.6508629  0.70464379 0.63254989 0.55796917\n",
      " 0.58862815 0.41599521 0.55599373 0.41872218 0.50122431 0.55953721\n",
      " 0.61882353 0.73486771 0.75921003 0.68307086 0.58626293 0.3971756\n",
      " 0.65489458 0.78545953 0.5956393  0.59915626 0.57396468 0.5378895\n",
      " 0.47954844 0.56043319 0.53834329 0.48052956 0.5447048  0.54594804\n",
      " 0.62218051 0.51707553 0.53022343 0.52337576 0.46813418 0.57087408\n",
      " 0.49042092 0.54417501 0.47912107 0.63154908 0.48642466 0.42546427\n",
      " 0.56738844 0.48782735 0.67688879 0.55972687 0.49993452 0.52156662\n",
      " 0.37220534 0.62050395 0.43133166 0.57010875 0.68237188 0.52665792\n",
      " 0.5560754  0.55640308 0.58622421 0.56622304 0.57684679 0.59047571\n",
      " 0.60583482 0.61358764 0.49637608 0.51168085 0.50478888 0.61470502\n",
      " 0.67621973 0.47719456 0.51161551 0.50825518 0.5617667  0.51424503\n",
      " 0.73114998 0.71434527 0.67737029 0.6405348  0.67610032 0.4077243\n",
      " 0.57276832 0.45569004 0.35628309 0.49299428 0.53024228 0.68789564\n",
      " 0.49590023 0.72927439 0.55964832 0.55497264 0.6821092  0.63921052\n",
      " 0.59606126 0.53603211 0.64603339 0.65611215 0.59741368 0.71932701\n",
      " 0.50985483 0.6268042  0.58251565 0.63222279 0.58188754 0.47583423\n",
      " 0.82813307 0.67278399 0.51883378 0.45682427 0.58219405 0.41229078\n",
      " 0.69558846 0.47814194 0.65465338 0.55982209 0.53043427 0.55681698\n",
      " 0.57112268 0.60728924 0.59350088 0.41138456 0.56856199 0.63185344\n",
      " 0.52395874 0.52622531 0.48971312 0.61030176 0.47234053 0.5643956\n",
      " 0.55224767 0.43803781 0.64371165 0.46996735 0.54174442 0.44900759\n",
      " 0.50428733 0.66163653 0.59644232 0.66775878 0.5710607  0.5323878\n",
      " 0.52687677 0.47930582 0.53563433 0.50797512 0.68567375 0.5729995\n",
      " 0.47207313 0.62782747 0.6107596  0.59777558 0.40973375 0.51962283\n",
      " 0.5773233  0.58367286 0.56056235 0.64342685 0.67192176 0.62998258\n",
      " 0.6936776  0.69032362 0.61458937 0.52655533 0.49102122 0.53192888\n",
      " 0.56569429 0.61248456 0.4596022  0.60066521 0.67099141 0.55291398\n",
      " 0.56876611 0.48780886 0.52201587 0.6410367  0.49318933 0.58636491\n",
      " 0.64579683 0.66860191 0.61919362 0.46616753 0.57862313 0.50469479\n",
      " 0.51556289 0.4791917  0.59968131 0.47745941 0.693736   0.54669623]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "from meta_data import DataSet, mate_data, model_select, cal_mate_data\n",
    "from QueryMetaData import QueryMetaData, QueryMetaData_classify\n",
    "\n",
    "dataset_path = './newdata/'\n",
    "\n",
    "# testdatasetnames = [ 'australian', 'clean1', 'ethn', 'blood', 'breast-cancer-wisc']\n",
    "testdatasetnames = ['australian']\n",
    "\n",
    "for testdataset in testdatasetnames:\n",
    "    print('***********currently dataset is : ', testdataset)\n",
    "    # metadata = np.load('./metadata/binary_metadata.npy')\n",
    "\n",
    "    # # compare the performace of different regressors\n",
    "\n",
    "    # # # LinearRegression\n",
    "    # print('train rfc')\n",
    "    # rfc = LogisticRegression()\n",
    "    # rfc.fit(metadata[:, 0:396], metadata[:, 396])\n",
    "    # print('done')\n",
    "\n",
    "    # active learning \n",
    "    dt = DataSet(testdataset, dataset_path)\n",
    "    X = dt.X\n",
    "    y = dt.y.ravel()\n",
    "    y = np.asarray(y, dtype=int)\n",
    "#     distance = dt.get_distance()\n",
    "    print(dt.n_samples)\n",
    "#     print(np.shape(distance))\n",
    "#     print(distance[0])\n",
    "#     print(distance[1])\n",
    "#     print(distance[-1])\n",
    "    node = dt.get_node_potential()\n",
    "    print(np.shape(node))\n",
    "    assert(dt.n_samples==np.shape(node)[0])\n",
    "\n",
    "#     print(node)\n",
    "    gra = dt.get_graph_density()\n",
    "    assert(dt.n_samples==np.shape(gra)[0])\n",
    "#     print(np.shape(gra))\n",
    "#     print(np.shape(dt.p_matrix))\n",
    "#     print(np.shape(dt.w_matrix))\n",
    "#     print(np.sum(dt.w_matrix,axis=1)[-20:-1])\n",
    "#     print(np.sum(dt.w_matrix,axis=0)[-20:-1])\n",
    "    print(gra)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
