{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Net(\n",
      "  (input_bn): BatchNorm1d(836, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (first_hidden): Linear(in_features=836, out_features=200, bias=True)\n",
      "  (first_bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (second_hidden): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (second_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
      "), Net(\n",
      "  (input_bn): BatchNorm1d(836, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (first_hidden): Linear(in_features=836, out_features=200, bias=True)\n",
      "  (first_bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (second_hidden): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (second_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
      ")]\n",
      "[Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0005\n",
      "), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0005\n",
      ")]\n",
      "MyLoss1()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "\n",
    "from MyNet import Net, MetaDataSet, MyLoss1, MyLoss\n",
    "\n",
    "# hyper parameters\n",
    "BATCH_SIZE = 10\n",
    "EPOCH_SIZE = 10\n",
    "\n",
    "LR = 1e-3\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY =  0.0005\n",
    "\n",
    "DATASET_SHUFFLE = False\n",
    "num_WORKERS = 2\n",
    "\n",
    "TASK = 'regression'\n",
    "\n",
    "XI = 0.0001\n",
    "\n",
    "\n",
    "save_path = './'\n",
    "metadata_dir = 'E:/metadata数据集/new_bigmetadata/australian/query_time/'\n",
    "\n",
    "# net = Net(n_feature=396, first_n_hidden=100, second_n_hidden=20, n_output=2)\n",
    "net_bn = Net(n_feature=836, first_n_hidden=200, second_n_hidden=100, n_output=1, batch_normalization=True)\n",
    "net_no_bn = Net(n_feature=836, first_n_hidden=200, second_n_hidden=100, n_output=1, batch_normalization=False)\n",
    "\n",
    "nets = [net_bn, net_no_bn]\n",
    "optimizers = [optim.Adam(net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY) for net in nets]\n",
    "criterion = MyLoss1(XI)\n",
    "print(nets)\n",
    "print(optimizers)\n",
    "print(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3285)\n",
      "tensor(-0.2587)\n",
      "tensor(0.0152)\n",
      "tensor(0.)\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# print('Preparing the dataset....')\n",
    "# loader = MetaDataSet(metadata_dir, BATCH_SIZE, num_WORKERS, TASK)\n",
    "# print(\"Dataset is ready!\")\n",
    "\n",
    "metadata = np.load('E:/metadata数据集/new_bigmetadata/australian/query_time/2australian30_big_metadata30.npy')\n",
    "\n",
    "# X = metadata[:, 0:396]\n",
    "# y = metadata[:, 396]\n",
    "X = metadata[:, 0:418]\n",
    "y = metadata[:, 418]\n",
    "# y[np.where(y>0)[0]] = 1\n",
    "# y[np.where(y<=0)[0]] = 0\n",
    "\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "X_tensor = X_tensor.float()\n",
    "y_tensor = y_tensor.float()\n",
    "print(torch.max(y_tensor))\n",
    "print(torch.min(y_tensor))\n",
    "print(torch.mean(y_tensor))\n",
    "\n",
    "print(torch.min(torch.abs(y_tensor)))\n",
    "\n",
    "print(X_tensor.dtype)\n",
    "print(y_tensor.dtype)\n",
    "# troch_dataset = Data.TensorDataset(data_tensor=X_tensor, target_tensor=y_tensor)\n",
    "troch_dataset = Data.TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "loader = Data.DataLoader(dataset=troch_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=DATASET_SHUFFLE,\n",
    "                        num_workers=num_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net 0  [1,  1000] loss: 0.212\n",
      "net 1  [1,  1000] loss: 0.895\n",
      "net 0  [1,  2000] loss: 0.054\n",
      "net 1  [1,  2000] loss: 0.015\n",
      "net 0  [2,  1000] loss: 0.022\n",
      "net 1  [2,  1000] loss: 0.003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-af992abbccd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#             print('loss ', loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                     \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tarining the NN\n",
    "for epoch in range(EPOCH_SIZE):\n",
    "    running_loss0 = 0.0\n",
    "    running_loss1 = 0.0\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "#         print('the shape of batch_X', batch_x.size())\n",
    "#         print('the shape of batch_y', batch_y.size())\n",
    "#         print(batch_x)\n",
    "        min_b = int(EPOCH_SIZE/2)\n",
    "        pari_X = torch.cat((batch_x[0:min_b,:],batch_x[min_b:,:]), 1)\n",
    "        pari_y = batch_y[0:min_b] - batch_y[min_b:]\n",
    "        for net, optimizer in zip(nets, optimizers):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(pari_X)\n",
    "            loss = criterion(outputs, pari_y)\n",
    "#             print('the dtype of loss ', loss.dtype)\n",
    "#             print('the shape of loss', loss.size())\n",
    "#             print('loss ', loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if net == nets[0]:\n",
    "                i = 0\n",
    "                # print statistics\n",
    "                running_loss0 += loss.item()\n",
    "                # print every 2000 mini-batches\n",
    "                if step % 1000 == 999:    \n",
    "                    print('net',i,' [%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, step + 1, running_loss0 / 2000))\n",
    "                    running_loss0 = 0.0\n",
    "            else:\n",
    "                i = 1\n",
    "                # print statistics\n",
    "                running_loss1 += loss.item()\n",
    "                # print every 2000 mini-batches\n",
    "                if step % 1000 == 999:    \n",
    "                    print('net',i,' [%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, step + 1, running_loss1 / 2000))\n",
    "                    running_loss1 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the parameters in NN\n",
    "torch.save({\n",
    "            'model_state_dict': nets[0].state_dict(),\n",
    "            'optimizer_state_dict': optimizers[0].state_dict(),\n",
    "            }, './regression_bn_net_parameters.pth')\n",
    "torch.save({\n",
    "            'model_state_dict': nets[1].state_dict(),\n",
    "            'optimizer_state_dict': optimizers[1].state_dict(),\n",
    "            }, './regression_nobn_net_parameters.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "param_groups\n",
      "0.001\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "op = optimizers[0]\n",
    "\n",
    "for x in op.state_dict().keys():\n",
    "    print(x)\n",
    "print(op.state_dict()['param_groups'][0]['lr'])\n",
    "pg = op.state_dict()['param_groups']\n",
    "print(pg[0]['lr'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pyroch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
