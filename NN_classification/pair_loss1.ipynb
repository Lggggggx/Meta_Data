{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Net_3hiddens(\n",
      "  (input_bn): BatchNorm1d(396, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (first_hidden): Linear(in_features=396, out_features=200, bias=True)\n",
      "  (first_bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (second_hidden): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (second_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (third_hidden): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (third_bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=50, out_features=1, bias=True)\n",
      "), Net_3hiddens(\n",
      "  (input_bn): BatchNorm1d(396, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (first_hidden): Linear(in_features=396, out_features=200, bias=True)\n",
      "  (first_bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (second_hidden): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (second_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (third_hidden): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (third_bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=50, out_features=1, bias=True)\n",
      ")]\n",
      "[SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      "), SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")]\n",
      "MyLoss()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "\n",
    "from MyNet import Net, MetaDataSet, MyLoss1, MyLoss, Net_3hiddens\n",
    "\n",
    "# hyper parameters\n",
    "BATCH_SIZE = 1000\n",
    "EPOCH_SIZE = 50\n",
    "\n",
    "LR = 1e-2\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY =  0.0005\n",
    "\n",
    "DATASET_SHUFFLE = False\n",
    "num_WORKERS = 3\n",
    "\n",
    "TASK = 'regression'\n",
    "\n",
    "LAMBDA = 1\n",
    "XI = 0.0005\n",
    "\n",
    "\n",
    "save_path = './'\n",
    "# metadata_dir = 'E:/metadata数据集/new_bigmetadata/australian/query_time/'\n",
    "metadata_dir = 'D:/generate_metadata/bigmetadata/australian/model1/query_time50/'\n",
    "\n",
    "\n",
    "# net = Net(n_feature=396, first_n_hidden=100, second_n_hidden=20, n_output=2)\n",
    "# net_bn = Net(n_feature=418, first_n_hidden=200, second_n_hidden=100, n_output=1, batch_normalization=True)\n",
    "# net_no_bn = Net(n_feature=418, first_n_hidden=200, second_n_hidden=100, n_output=1, batch_normalization=False)\n",
    "net3_bn = Net_3hiddens(n_feature=396, first_n_hidden=200, second_n_hidden=100, third_n_hidden=50, n_output=1, batch_normalization=True)\n",
    "net3_no_bn = Net_3hiddens(n_feature=396, first_n_hidden=200, second_n_hidden=100, third_n_hidden=50, n_output=1, batch_normalization=False)\n",
    "\n",
    "nets = [net3_bn, net3_no_bn]\n",
    "# optimizers = [optim.Adam(net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY) for net in nets]\n",
    "optimizers = [optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY) for net in nets]\n",
    "\n",
    "criterion = MyLoss(XI)\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "print(nets)\n",
    "print(optimizers)\n",
    "print(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Preparing the dataset....')\n",
    "# loader = MetaDataSet(metadata_dir, BATCH_SIZE, num_WORKERS, DATASET_SHUFFLE, TASK)\n",
    "# print(\"Dataset is ready!\")\n",
    "\n",
    "metadata = np.load('D:/generate_metadata/bigmetadata/australian/model1/query_time50/2australian30_big_metadata50.npy')\n",
    "# metadata2 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/4australian30_big_metadata30.npy')\n",
    "# metadata3 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/10australian30_big_metadata30.npy')\n",
    "# metadata4 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/20australian30_big_metadata30.npy')\n",
    "# metadata5 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/30australian30_big_metadata30.npy')\n",
    "# metadata6 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/48australian30_big_metadata30.npy')\n",
    "\n",
    "# metadata = np.vstack((metadata1, metadata2, metadata3, metadata4, metadata5, metadata6))\n",
    "\n",
    "X = metadata[:, 0:396]\n",
    "y = metadata[:, 396]\n",
    "\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "X_tensor = X_tensor.float()\n",
    "y_tensor = y_tensor.float()\n",
    "\n",
    "troch_dataset = Data.TensorDataset(X_tensor, y_tensor)\n",
    "loader = Data.DataLoader(dataset=troch_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=DATASET_SHUFFLE,\n",
    "                        num_workers=num_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net 0  [1,    20] loss: nan\n",
      "net 1  [1,    20] loss: nan\n",
      "net 0  [2,    20] loss: nan\n",
      "net 1  [2,    20] loss: nan\n",
      "net 0  [3,    20] loss: nan\n",
      "net 1  [3,    20] loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f663393a585b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mrunning_loss0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mrunning_loss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#         print('step',step)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mmin_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    857\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;31m# request that overlapped reads stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tarining the NN\n",
    "for epoch in range(200):\n",
    "    running_loss0 = 0.0\n",
    "    running_loss1 = 0.0\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "#         print('step',step)\n",
    "        min_b = int(BATCH_SIZE/2)\n",
    "        pari_y = batch_y[0:min_b] - batch_y[min_b:]\n",
    "#         pari_y = \n",
    "#         if step % 20 == 19:    \n",
    "#             print('min pari_y',min(pari_y))\n",
    "#             print('max pari_y',max(pari_y))\n",
    "#             print('abs min pari_y',min(abs(pari_y)))\n",
    "#             print('abs max pari_y',max(abs(pari_y)))\n",
    "        for net, optimizer in zip(nets, optimizers):\n",
    "            optimizer.zero_grad()\n",
    "            output1 = net(batch_x[0:min_b,:])\n",
    "            output2 = net(batch_x[min_b:,:])\n",
    "            loss = criterion(output1, output2, pari_y) + mse_loss(torch.cat((output1, output2))[:,0], batch_y)\n",
    "#             loss = mse_loss(torch.cat((output1, output2))[:,0], batch_y)\n",
    "#             print(loss)\n",
    "\n",
    "#             print('the dtype of loss ', loss.dtype)\n",
    "#             print('the shape of loss', loss.size())\n",
    "#             print('loss ', loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if net == nets[0]:\n",
    "                i = 0\n",
    "                # print statistics\n",
    "                running_loss0 += loss.item()\n",
    "                # print every 2000 mini-batches\n",
    "                if step % 20 == 19:    \n",
    "                    print('net',i,' [%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, step + 1, running_loss0 / 2000))\n",
    "                    running_loss0 = 0.0\n",
    "            else:\n",
    "                i = 1\n",
    "                # print statistics\n",
    "                running_loss1 += loss.item()\n",
    "                # print every 2000 mini-batches\n",
    "                if step % 20 == 19:    \n",
    "                    print('net',i,' [%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, step + 1, running_loss1 / 2000))\n",
    "                    running_loss1 = 0.0          \n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "# ranking accuracy.\n",
    "net2 = nets[1]\n",
    "# print(net2)\n",
    "n_sample = metadata.shape[0]\n",
    "X = metadata[:, 0:396]\n",
    "X_tensor = torch.from_numpy(X)\n",
    "X_tensor = X_tensor.float()\n",
    "y = metadata[:, 396]\n",
    "print('y-------',y)\n",
    "# pair_X = [np.hstack((X[i,:],X[i+1,:])) for i in range(0, n_sample, 2)]\n",
    "pair_y = [(y[i]-y[i+1]) for i in range(0, n_sample, 2)]\n",
    "pair_y = np.array(pair_y)\n",
    "pair_y[np.where(pair_y>0)[0]] = 1\n",
    "pair_y[np.where(pair_y<=0)[0]] = 0\n",
    "out = net2(X_tensor)\n",
    "\n",
    "pred = out.detach().numpy()\n",
    "print('pred**********',pred)\n",
    "pred = pred[:,0]\n",
    "print('r2 score : ',r2_score(y, pred))\n",
    "pred = [(pred[i]-pred[i+1]) for i in range(0, n_sample, 2)]\n",
    "pred = np.array(pred)\n",
    "pred[np.where(pred>0)[0]] = 1\n",
    "pred[np.where(pred<=0)[0]] = 0\n",
    "print(np.shape(pair_y))\n",
    "# pair_X_tensor = torch.from_numpy(pair_X)\n",
    "# pair_y_tensor = torch.from_numpy(pair_y)\n",
    "print(accuracy_score(pair_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the parameters in NN\n",
    "torch.save({\n",
    "            'model_state_dict': nets[0].state_dict(),\n",
    "            'optimizer_state_dict': optimizers[0].state_dict(),\n",
    "            }, './pairloss_bn_net_parameters.pth')\n",
    "torch.save({\n",
    "            'model_state_dict': nets[1].state_dict(),\n",
    "            'optimizer_state_dict': optimizers[1].state_dict(),\n",
    "            }, './pairloss_nobn_net_parameters.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 测试数据集\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "\n",
    "metadata1 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/2australian30_big_metadata30.npy')\n",
    "metadata2 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/4australian30_big_metadata30.npy')\n",
    "metadata3 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/10australian30_big_metadata30.npy')\n",
    "metadata4 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/20australian30_big_metadata30.npy')\n",
    "metadata5 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/30australian30_big_metadata30.npy')\n",
    "metadata6 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/48australian30_big_metadata30.npy')\n",
    "\n",
    "metadata = np.vstack((metadata1, metadata2, metadata3, metadata4, metadata5, metadata6 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162000,)\n",
      "torch.Size([162000, 1])\n",
      "(162000, 1)\n",
      "(162000,)\n",
      "-0.03237689474503469\n",
      "0.5459259259259259\n"
     ]
    }
   ],
   "source": [
    "# 普通回归测试\n",
    "net2 = nets[1]\n",
    "# X = metadata[:, 0:396]\n",
    "# y = metadata[:, 396]\n",
    "X = metadata[:, 0:418]\n",
    "y = metadata[:, 418]\n",
    "print(y.shape)\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "X_tensor = X_tensor.float()\n",
    "y_tensor = y_tensor.float()\n",
    "out = net2(X_tensor)\n",
    "print(out.size())\n",
    "pred = out.detach().numpy()\n",
    "print(pred.shape)\n",
    "print(pred[:,0].shape)\n",
    "# print(predict)\n",
    "# print(accuracy_score(y, predict))\n",
    "print(r2_score(y, pred[:,0]))\n",
    "y[np.where(y>0)[0]] = 1\n",
    "y[np.where(y<=0)[0]] = 0\n",
    "cperd = pred[:,0]\n",
    "cperd[np.where(cperd>0)[0]] = 1\n",
    "cperd[np.where(cperd<=0)[0]] = 0\n",
    "print(accuracy_score(y, cperd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.9000e+02,  6.5367e+00,  4.2000e+01,  ..., -4.4707e-01,\n",
      "         -5.0195e-01, -6.1290e-01],\n",
      "        [ 6.9000e+02,  6.5367e+00,  4.2000e+01,  ..., -1.0543e-01,\n",
      "         -1.5824e-01, -2.1628e-01],\n",
      "        [ 6.9000e+02,  6.5367e+00,  4.2000e+01,  ...,  1.0560e-01,\n",
      "          4.7534e-02, -9.0591e-03],\n",
      "        ...,\n",
      "        [ 6.9000e+02,  6.5367e+00,  4.2000e+01,  ..., -1.2116e-01,\n",
      "         -1.9615e-01, -2.6588e-01],\n",
      "        [ 6.9000e+02,  6.5367e+00,  4.2000e+01,  ...,  1.6786e-01,\n",
      "          1.1049e-01,  4.1618e-02],\n",
      "        [ 6.9000e+02,  6.5367e+00,  4.2000e+01,  ..., -6.1331e-01,\n",
      "         -6.7973e-01, -7.7335e-01]])\n",
      "[tensor([ 6.9000e+02,  6.5367e+00,  4.2000e+01,  3.7377e+00,  6.0870e-02,\n",
      "        -2.7990e+00,  1.6429e+01,  2.7990e+00, -2.7784e+00,  1.8493e+01,\n",
      "         4.8629e+00,  5.4844e+00, -1.9914e+00,  3.4000e+02,  5.3920e+01,\n",
      "         9.6326e+01,  9.5317e-01,  1.1570e+00, -4.7184e-01,  9.2812e-02,\n",
      "        -2.5425e-01,  6.2991e-01,  4.2000e+01,  5.0000e-01,  5.0000e-01,\n",
      "         6.5976e-01,  3.4024e-01,  0.0000e+00,  3.1733e-01,  4.3767e-01,\n",
      "         6.2434e-01,  7.0873e-01,  7.1394e-01,  7.1554e-01,  9.3095e-01,\n",
      "         9.9505e-01,  1.0000e+00,  6.8725e-01,  6.8725e-01,  7.4562e-01,\n",
      "         0.0000e+00,  7.5141e-01,  4.7349e-01,  4.7349e-01,  8.2571e-01,\n",
      "         5.9179e-01,  1.0000e+00,  0.0000e+00,  2.5153e-01,  6.3788e-01,\n",
      "         1.0000e+00,  8.2234e-01,  6.3834e-01,  8.3540e-01,  8.2702e-01,\n",
      "         4.5587e-01,  8.2560e-01,  3.3333e-01,  2.5000e-01,  4.0000e-01,\n",
      "         5.0000e-01,  5.7143e-01,  5.0000e-01,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.6667e-01,\n",
      "         7.5000e-01,  6.0000e-01,  5.0000e-01,  4.2857e-01,  5.0000e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.1989e-01,  2.1989e-01,  2.1989e-01,  1.0000e+00,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5452e-02,\n",
      "         8.5452e-02,  2.2869e-01,  2.2869e-01,  2.2869e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  1.9335e-02,  1.9335e-02,\n",
      "         2.7957e-01,  2.7957e-01,  8.9671e-01,  8.9671e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  4.7479e-02,  4.7479e-02,\n",
      "         2.9250e-01,  7.6260e-01,  7.6260e-01,  8.4877e-01,  8.4877e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  3.3845e-02,  3.1224e-01,\n",
      "         3.1224e-01,  8.6790e-01,  8.8364e-01,  8.8364e-01,  9.7087e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  5.9691e-02,  2.6484e-01,\n",
      "         3.3805e-01,  7.5220e-01,  7.5220e-01,  8.6490e-01,  8.8127e-01,\n",
      "         1.0000e+00,  3.6597e-01,  2.8570e-01,  4.3912e-01,  4.6102e-01,\n",
      "         5.2644e-01,  4.9132e-01,  4.2494e-01,  3.6814e-01,  4.2860e-01,\n",
      "         3.9606e-01,  4.1015e-01,  3.7820e-01,  6.5889e-01,  6.6082e-01,\n",
      "         6.5982e-01,  6.5882e-01,  6.5782e-01,  6.5976e-01,  3.4111e-01,\n",
      "         3.3918e-01,  3.4018e-01,  3.4118e-01,  3.4218e-01,  3.4024e-01,\n",
      "         0.0000e+00,  1.7549e-01,  2.6181e-01,  3.0667e-01,  3.7220e-01,\n",
      "         4.1430e-01,  5.2332e-01,  5.8068e-01,  6.6534e-01,  7.0240e-01,\n",
      "         0.0000e+00,  1.4001e-01,  2.1073e-01,  2.7230e-01,  3.1877e-01,\n",
      "         3.7984e-01,  4.5691e-01,  5.4666e-01,  6.0346e-01,  6.6408e-01,\n",
      "         0.0000e+00,  2.0564e-01,  3.3437e-01,  4.2444e-01,  4.8376e-01,\n",
      "         5.3338e-01,  5.9877e-01,  6.6063e-01,  7.0419e-01,  7.8616e-01,\n",
      "         0.0000e+00,  2.6068e-01,  3.8710e-01,  4.4633e-01,  5.1086e-01,\n",
      "         5.5858e-01,  6.2480e-01,  6.7529e-01,  7.4521e-01,  8.4785e-01,\n",
      "         0.0000e+00,  2.8393e-01,  4.1720e-01,  4.9537e-01,  5.3907e-01,\n",
      "         5.9669e-01,  6.4073e-01,  7.0480e-01,  7.7508e-01,  8.5840e-01,\n",
      "         0.0000e+00,  1.7864e-01,  2.7728e-01,  4.0065e-01,  5.0051e-01,\n",
      "         5.6393e-01,  6.1246e-01,  6.7575e-01,  7.3286e-01,  8.4835e-01,\n",
      "         4.0022e-01,  3.5928e-01,  4.7314e-01,  5.0567e-01,  5.3113e-01,\n",
      "         4.7904e-01,  2.1187e-01,  2.0150e-01,  2.2871e-01,  2.3528e-01,\n",
      "         2.3888e-01,  2.5131e-01, -3.0782e-01, -1.0298e-01, -2.3605e-01,\n",
      "        -2.3669e-01, -3.4870e-01, -4.8369e-01, -5.0275e-01,  2.1452e-02,\n",
      "        -2.3591e-01, -4.9740e-01, -4.0521e-01, -6.3759e-02, -2.2191e-01,\n",
      "        -2.2115e-01, -3.0026e-01, -3.9467e-01, -5.0102e-01,  6.1902e-02,\n",
      "        -1.4567e-01, -4.0612e-01, -3.4730e-01,  7.9543e-02, -1.7142e-01,\n",
      "        -1.6764e-01,  1.0514e-01, -2.8541e-02, -1.5246e-01,  4.8740e-01,\n",
      "         1.3687e-01, -4.4539e-02,  4.9073e-02,  3.5412e-02, -1.9060e-01,\n",
      "        -1.8877e-01,  5.7029e-02, -6.2849e-02, -1.7656e-01,  3.8756e-01,\n",
      "        -2.8024e-01, -3.8234e-01, -3.1929e-01,  6.7672e-02, -1.5615e-01,\n",
      "        -2.2090e-01,  1.4402e-01,  1.8500e-02, -9.4709e-02,  4.0589e-01,\n",
      "        -2.3174e-01, -2.5258e-01, -1.8839e-01,  1.6056e-02, -4.0498e-01,\n",
      "        -4.9747e-01, -1.0502e-01, -3.2122e-01, -4.1408e-01,  5.2546e-02,\n",
      "        -5.8821e-01, -5.9355e-01, -4.4859e-01,  2.1847e-01,  2.1847e-01,\n",
      "        -1.9701e-02,  0.0000e+00, -1.4235e-03, -1.1783e-01, -1.1783e-01,\n",
      "        -7.8153e-01, -1.4337e-01, -2.4606e-01,  1.8417e-01,  1.8417e-01,\n",
      "         9.8713e-02,  0.0000e+00, -4.4522e-02, -1.4276e-01, -1.4276e-01,\n",
      "        -8.1583e-01, -1.6282e-01, -2.2978e-01,  5.3964e-01,  5.3964e-01,\n",
      "         5.2275e-01,  0.0000e+00,  2.9554e-01, -2.4329e-01, -2.4329e-01,\n",
      "        -3.3348e-01, -2.5723e-01,  2.1060e-02,  4.7368e-01,  4.7368e-01,\n",
      "         4.3068e-01,  0.0000e+00,  2.0874e-01, -2.1707e-01, -2.1707e-01,\n",
      "        -2.9512e-01, -2.3171e-01, -4.3210e-01,  5.5146e-01,  5.5146e-01,\n",
      "         5.2244e-01,  0.0000e+00,  2.8377e-01, -2.0610e-01, -2.0610e-01,\n",
      "        -1.9261e-01, -2.8089e-01, -3.0586e-01,  2.2772e-01,  2.2772e-01,\n",
      "         1.7639e-01,  0.0000e+00, -6.2948e-02, -4.1905e-01, -4.1905e-01,\n",
      "        -5.1595e-01, -5.3003e-01, -6.3211e-01, -5.0528e-02,  4.6292e-02,\n",
      "        -2.9945e-01, -1.1858e-01, -3.4850e-01, -3.5803e-01, -4.6930e-01,\n",
      "        -6.9512e-01, -2.4369e-01, -6.6221e-01,  3.5625e-02,  3.5411e-02,\n",
      "        -2.7913e-01, -1.2935e-01, -3.8402e-01, -3.0870e-01, -4.7105e-01,\n",
      "        -7.3691e-01, -2.2815e-01, -7.2531e-01,  4.1690e-01,  2.5373e-01,\n",
      "         1.4776e-01,  1.5503e-01, -1.5401e-03, -9.9811e-02, -1.1452e-01,\n",
      "        -2.5043e-01, -1.7119e-01, -4.0673e-01,  3.2494e-01,  2.0055e-01,\n",
      "         9.1929e-02,  6.5687e-02, -3.3814e-02, -8.9935e-02, -1.4279e-01,\n",
      "        -2.2260e-01, -1.9176e-01, -3.2662e-01,  4.0834e-01,  2.4433e-01,\n",
      "         1.0264e-01,  1.3436e-01,  5.3281e-02, -4.1821e-02, -6.2541e-02,\n",
      "        -1.2091e-01, -2.2393e-01, -3.0384e-01,  2.0216e-01,  3.0528e-02,\n",
      "        -6.4240e-02, -1.8277e-01, -2.7871e-01, -3.3964e-01, -3.8627e-01,\n",
      "        -4.4707e-01, -5.0195e-01, -6.1290e-01]), tensor([ 6.9000e+02,  6.5367e+00,  4.2000e+01,  3.7377e+00,  6.0870e-02,\n",
      "        -2.7990e+00,  1.6429e+01,  2.7990e+00, -2.7784e+00,  1.8493e+01,\n",
      "         4.8629e+00,  5.4844e+00, -1.9914e+00,  3.4000e+02,  5.3920e+01,\n",
      "         9.6326e+01,  9.5317e-01,  1.1570e+00, -4.7184e-01,  9.0187e-13,\n",
      "        -2.5425e-01,  4.9238e-01,  4.2000e+01,  6.2500e-01,  3.7500e-01,\n",
      "         9.2604e-01,  7.3964e-02,  0.0000e+00,  1.6729e-01,  3.3280e-01,\n",
      "         3.3426e-01,  3.3462e-01,  3.3872e-01,  4.9574e-01,  8.8320e-01,\n",
      "         8.8356e-01,  1.0000e+00,  8.9935e-01,  8.9935e-01,  8.0093e-01,\n",
      "         8.1756e-01,  7.4494e-01,  7.3910e-01,  7.3910e-01,  1.0000e+00,\n",
      "         6.7390e-01,  0.0000e+00,  3.8596e-01,  1.9639e-01,  4.0317e-01,\n",
      "         2.0116e-02,  1.0000e+00,  8.2932e-04,  1.9855e-01,  1.9931e-01,\n",
      "         1.9824e-01,  0.0000e+00,  3.3333e-01,  2.5000e-01,  4.0000e-01,\n",
      "         5.0000e-01,  5.7143e-01,  6.2500e-01,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.6667e-01,\n",
      "         7.5000e-01,  6.0000e-01,  5.0000e-01,  4.2857e-01,  3.7500e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.1989e-01,  2.1989e-01,  2.1989e-01,  1.0000e+00,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5452e-02,\n",
      "         8.5452e-02,  2.2869e-01,  2.2869e-01,  2.2869e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  1.9335e-02,  1.9335e-02,\n",
      "         2.7957e-01,  2.7957e-01,  8.9671e-01,  8.9671e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  4.7479e-02,  4.7479e-02,\n",
      "         2.9250e-01,  7.6260e-01,  7.6260e-01,  8.4877e-01,  8.4877e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  3.3845e-02,  3.1224e-01,\n",
      "         3.1224e-01,  8.6790e-01,  8.8364e-01,  8.8364e-01,  9.7087e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  5.9183e-02,  3.0199e-01,\n",
      "         8.5312e-01,  8.6050e-01,  8.6050e-01,  9.4131e-01,  9.6279e-01,\n",
      "         1.0000e+00,  3.6597e-01,  2.8570e-01,  4.3912e-01,  4.6102e-01,\n",
      "         5.2644e-01,  5.8394e-01,  4.2494e-01,  3.6814e-01,  4.2860e-01,\n",
      "         3.9606e-01,  4.1015e-01,  4.1311e-01,  9.2420e-01,  9.2690e-01,\n",
      "         9.2669e-01,  9.2647e-01,  9.2625e-01,  9.2604e-01,  7.5802e-02,\n",
      "         7.3099e-02,  7.3314e-02,  7.3529e-02,  7.3746e-02,  7.3964e-02,\n",
      "         0.0000e+00,  1.7549e-01,  2.6181e-01,  3.0667e-01,  3.7220e-01,\n",
      "         4.1430e-01,  5.2332e-01,  5.8068e-01,  6.6534e-01,  7.0240e-01,\n",
      "         0.0000e+00,  1.4001e-01,  2.1073e-01,  2.7230e-01,  3.1877e-01,\n",
      "         3.7984e-01,  4.5691e-01,  5.4666e-01,  6.0346e-01,  6.6408e-01,\n",
      "         0.0000e+00,  2.0564e-01,  3.3437e-01,  4.2444e-01,  4.8376e-01,\n",
      "         5.3338e-01,  5.9877e-01,  6.6063e-01,  7.0419e-01,  7.8616e-01,\n",
      "         0.0000e+00,  2.6068e-01,  3.8710e-01,  4.4633e-01,  5.1086e-01,\n",
      "         5.5858e-01,  6.2480e-01,  6.7529e-01,  7.4521e-01,  8.4785e-01,\n",
      "         0.0000e+00,  2.8393e-01,  4.1720e-01,  4.9537e-01,  5.3907e-01,\n",
      "         5.9669e-01,  6.4073e-01,  7.0480e-01,  7.7508e-01,  8.5840e-01,\n",
      "         0.0000e+00,  3.4094e-01,  4.8925e-01,  5.6392e-01,  6.1214e-01,\n",
      "         6.6522e-01,  7.1203e-01,  7.6413e-01,  8.2681e-01,  8.8790e-01,\n",
      "         4.0022e-01,  3.5928e-01,  4.7314e-01,  5.0567e-01,  5.3113e-01,\n",
      "         5.8623e-01,  2.1187e-01,  2.0150e-01,  2.2871e-01,  2.3528e-01,\n",
      "         2.3888e-01,  2.4840e-01,  6.9245e-01,  2.9346e-01,  1.5975e-01,\n",
      "        -1.0631e-01, -8.7256e-02,  4.1789e-01,  1.6039e-01,  4.7734e-02,\n",
      "        -8.7724e-03, -1.0097e-01,  1.6052e-01,  2.7679e-01,  1.1940e-01,\n",
      "        -1.6046e-01, -5.4114e-02,  4.0245e-01,  1.1864e-01,  4.0288e-02,\n",
      "        -6.7529e-03, -6.5567e-02,  1.9488e-01,  2.1688e-01, -3.0305e-02,\n",
      "        -1.5122e-02,  1.0880e-01,  6.2474e-01, -3.4080e-02,  2.4248e-01,\n",
      "         1.8641e-01,  9.2798e-02,  2.7420e-01,  1.6050e-01, -6.3680e-02,\n",
      "        -5.1467e-02,  6.2243e-02,  5.1265e-01, -6.5512e-02,  1.8212e-01,\n",
      "        -1.9420e-01, -2.5725e-01, -1.5514e-01,  2.1607e-01, -7.2504e-02,\n",
      "         5.3684e-02,  1.6689e-01,  5.5428e-01, -7.7579e-03,  2.9241e-01,\n",
      "        -4.0000e-02, -1.0419e-01, -8.3348e-02,  2.7047e-01,  6.7503e-02,\n",
      "         1.5610e-01,  2.6383e-01,  6.0710e-01,  1.5485e-01,  3.8471e-01,\n",
      "         5.8673e-02,  4.1104e-02,  9.6976e-02,  6.1490e-01,  6.1490e-01,\n",
      "         3.7674e-01,  3.9501e-01,  2.7861e-01, -3.8510e-01, -3.8510e-01,\n",
      "         1.5037e-01,  2.5307e-01,  0.0000e+00,  5.2472e-01,  5.2472e-01,\n",
      "         4.3926e-01,  2.9603e-01,  1.9779e-01, -4.7528e-01, -4.7528e-01,\n",
      "         1.1077e-01,  1.7773e-01,  0.0000e+00,  6.7697e-01,  6.7697e-01,\n",
      "         6.6009e-01,  4.3288e-01, -1.0595e-01, -1.9614e-01, -1.9614e-01,\n",
      "         1.5840e-01, -1.1989e-01,  0.0000e+00,  5.9877e-01,  5.9877e-01,\n",
      "         5.5577e-01,  3.3383e-01, -9.1977e-02, -1.7003e-01, -1.7003e-01,\n",
      "        -3.0701e-01, -1.0661e-01,  0.0000e+00,  6.9985e-01,  6.9985e-01,\n",
      "         6.7084e-01,  4.3217e-01, -5.7711e-02, -4.4221e-02, -4.4221e-02,\n",
      "        -1.5747e-01, -1.3250e-01,  0.0000e+00,  8.8710e-01,  8.8710e-01,\n",
      "         8.3460e-01,  6.1920e-01,  1.3029e-01,  1.2375e-01,  1.2375e-01,\n",
      "         5.2066e-02,  3.3011e-02,  0.0000e+00,  4.4556e-01,  1.4950e-01,\n",
      "         1.8309e-01,  4.7934e-02,  1.7448e-01,  1.7633e-01, -3.4497e-01,\n",
      "         2.4522e-01, -2.7690e-01, -2.5472e-01,  4.1996e-01,  1.0963e-01,\n",
      "         1.3728e-01, -4.3467e-02,  1.4169e-01,  1.3071e-01, -4.3643e-01,\n",
      "         1.7077e-01, -3.9540e-01, -3.7646e-01,  6.4956e-01,  3.5031e-01,\n",
      "         1.7965e-01,  1.3580e-01,  3.6390e-01,  1.8739e-01, -1.5768e-01,\n",
      "        -1.3261e-01, -2.7881e-01, -2.6211e-01,  5.3947e-01,  2.8911e-01,\n",
      "         8.6160e-02,  9.1277e-02, -3.7864e-02,  9.1342e-02, -1.3668e-01,\n",
      "        -1.1736e-01, -2.0991e-01, -1.9425e-01,  6.5599e-01,  4.0512e-01,\n",
      "         1.7611e-01,  2.0167e-01,  1.2371e-01,  9.9537e-02, -1.2021e-02,\n",
      "        -8.2460e-02, -1.0775e-01, -1.4858e-01,  8.1347e-01,  4.9763e-01,\n",
      "         3.6024e-01,  2.9107e-01,  2.4640e-01,  1.9723e-01,  1.5387e-01,\n",
      "         1.0560e-01,  4.7534e-02, -9.0591e-03]), tensor([ 6.9000e+02,  6.5367e+00,  4.2000e+01,  3.7377e+00,  6.0870e-02,\n",
      "        -2.7990e+00,  1.6429e+01,  2.7990e+00, -2.7784e+00,  1.8493e+01,\n",
      "         4.8629e+00,  5.4844e+00, -1.9914e+00,  3.4000e+02,  5.3920e+01,\n",
      "         9.6326e+01,  9.5317e-01,  1.1570e+00, -4.7184e-01,  1.0409e+00,\n",
      "        -2.5425e-01,  5.8863e-01,  4.2000e+01,  5.0000e-01,  5.0000e-01,\n",
      "         5.6213e-01,  4.3787e-01,  0.0000e+00,  4.6129e-01,  5.8356e-01,\n",
      "         6.9328e-01,  6.9540e-01,  8.9769e-01,  8.9913e-01,  8.9951e-01,\n",
      "         9.0527e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00,  9.1333e-01,\n",
      "         8.2641e-01,  0.0000e+00,  5.2602e-01,  5.2602e-01,  7.4398e-01,\n",
      "         8.0353e-01,  8.5832e-01,  1.8541e-01,  1.0000e+00,  8.9289e-01,\n",
      "         4.4445e-01,  4.6781e-01,  1.7529e-01,  1.8064e-01,  6.8255e-01,\n",
      "         7.8530e-01,  0.0000e+00,  3.3333e-01,  2.5000e-01,  4.0000e-01,\n",
      "         5.0000e-01,  5.7143e-01,  5.0000e-01,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.6667e-01,\n",
      "         7.5000e-01,  6.0000e-01,  5.0000e-01,  4.2857e-01,  5.0000e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.1989e-01,  2.1989e-01,  2.1989e-01,  1.0000e+00,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5452e-02,\n",
      "         8.5452e-02,  2.2869e-01,  2.2869e-01,  2.2869e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  1.9335e-02,  1.9335e-02,\n",
      "         2.7957e-01,  2.7957e-01,  8.9671e-01,  8.9671e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  4.7479e-02,  4.7479e-02,\n",
      "         2.9250e-01,  7.6260e-01,  7.6260e-01,  8.4877e-01,  8.4877e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  3.3845e-02,  3.1224e-01,\n",
      "         3.1224e-01,  8.6790e-01,  8.8364e-01,  8.8364e-01,  9.7087e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  3.7843e-03,  2.9655e-01,\n",
      "         4.1758e-01,  7.3799e-01,  7.3799e-01,  7.9721e-01,  9.6391e-01,\n",
      "         1.0000e+00,  3.6597e-01,  2.8570e-01,  4.3912e-01,  4.6102e-01,\n",
      "         5.2644e-01,  4.9550e-01,  4.2494e-01,  3.6814e-01,  4.2860e-01,\n",
      "         3.9606e-01,  4.1015e-01,  3.8224e-01,  5.6268e-01,  5.6433e-01,\n",
      "         5.6305e-01,  5.6176e-01,  5.6047e-01,  5.6213e-01,  4.3732e-01,\n",
      "         4.3567e-01,  4.3695e-01,  4.3824e-01,  4.3953e-01,  4.3787e-01,\n",
      "         0.0000e+00,  1.7549e-01,  2.6181e-01,  3.0667e-01,  3.7220e-01,\n",
      "         4.1430e-01,  5.2332e-01,  5.8068e-01,  6.6534e-01,  7.0240e-01,\n",
      "         0.0000e+00,  1.4001e-01,  2.1073e-01,  2.7230e-01,  3.1877e-01,\n",
      "         3.7984e-01,  4.5691e-01,  5.4666e-01,  6.0346e-01,  6.6408e-01,\n",
      "         0.0000e+00,  2.0564e-01,  3.3437e-01,  4.2444e-01,  4.8376e-01,\n",
      "         5.3338e-01,  5.9877e-01,  6.6063e-01,  7.0419e-01,  7.8616e-01,\n",
      "         0.0000e+00,  2.6068e-01,  3.8710e-01,  4.4633e-01,  5.1086e-01,\n",
      "         5.5858e-01,  6.2480e-01,  6.7529e-01,  7.4521e-01,  8.4785e-01,\n",
      "         0.0000e+00,  2.8393e-01,  4.1720e-01,  4.9537e-01,  5.3907e-01,\n",
      "         5.9669e-01,  6.4073e-01,  7.0480e-01,  7.7508e-01,  8.5840e-01,\n",
      "         0.0000e+00,  2.2797e-01,  3.6602e-01,  4.4229e-01,  4.7843e-01,\n",
      "         5.4309e-01,  5.8071e-01,  6.4880e-01,  7.0382e-01,  7.7584e-01,\n",
      "         4.0022e-01,  3.5928e-01,  4.7314e-01,  5.0567e-01,  5.3113e-01,\n",
      "         4.7670e-01,  2.1187e-01,  2.0150e-01,  2.2871e-01,  2.3528e-01,\n",
      "         2.3888e-01,  2.2101e-01, -1.0670e-01,  2.6963e-01,  8.1352e-03,\n",
      "         2.6885e-01,  2.6949e-01,  1.0033e-01,  2.7897e-03,  5.2699e-01,\n",
      "         2.1848e-02,  4.0256e-01,  1.5684e-01,  3.5843e-01,  9.7985e-02,\n",
      "         2.8295e-01,  2.8219e-01,  1.5680e-01,  3.0875e-03,  5.6601e-01,\n",
      "         1.0944e-01,  4.4034e-01,  2.0384e-01,  3.0115e-01,  1.1974e-01,\n",
      "        -3.3596e-03, -7.1342e-03,  2.1336e-01,  1.1824e-02,  6.5168e-01,\n",
      "         1.3574e-01,  2.4383e-01,  2.6942e-01,  1.7995e-01,  7.7849e-02,\n",
      "         2.7142e-01,  2.6959e-01,  1.4090e-01,  2.8363e-01,  8.4775e-01,\n",
      "         3.9734e-01,  4.9560e-01,  5.1722e-01,  1.4137e-01,  1.2053e-01,\n",
      "         1.5221e-01,  2.1696e-01,  1.8472e-01,  2.7840e-01,  7.7900e-01,\n",
      "         3.9161e-01,  4.4078e-01,  5.1713e-01,  7.4978e-02, -1.3592e-01,\n",
      "        -3.1218e-01, -3.6668e-01, -5.1195e-02, -3.1014e-01,  3.3087e-01,\n",
      "        -2.0137e-01, -1.4521e-01, -7.7858e-02,  7.2401e-01,  7.2401e-01,\n",
      "         4.8584e-01,  5.0412e-01,  0.0000e+00,  2.5948e-01,  2.5948e-01,\n",
      "        -2.7599e-01,  3.6217e-01,  3.8771e-01,  6.8827e-01,  6.8827e-01,\n",
      "         6.0282e-01,  4.5958e-01,  0.0000e+00,  2.7432e-01,  2.7432e-01,\n",
      "        -3.1173e-01,  3.4129e-01,  3.6134e-01,  7.0392e-01,  7.0392e-01,\n",
      "         6.8704e-01,  4.5982e-01,  0.0000e+00,  1.8534e-01,  1.8534e-01,\n",
      "        -1.6919e-01, -9.2946e-02, -7.9008e-02,  9.3387e-01,  9.3387e-01,\n",
      "         8.9087e-01,  6.6893e-01,  0.0000e+00,  2.8092e-02,  2.8092e-02,\n",
      "         1.6507e-01,  2.2848e-01,  2.4312e-01,  9.2457e-01,  9.2457e-01,\n",
      "         8.9555e-01,  6.5688e-01,  0.0000e+00,  6.7248e-02,  6.7248e-02,\n",
      "         1.8050e-01,  9.2222e-02,  1.6701e-01,  3.2186e-01,  3.2186e-01,\n",
      "         3.1895e-01,  9.3291e-02,  0.0000e+00, -2.4697e-01, -2.4697e-01,\n",
      "        -2.9261e-01, -4.2110e-01, -4.4892e-01,  5.6831e-01,  3.3815e-01,\n",
      "         4.3575e-01,  2.4240e-01,  3.0691e-01,  5.3193e-02,  1.4979e-02,\n",
      "         2.3399e-02,  3.5494e-01,  3.5586e-01,  5.9277e-01,  3.8757e-01,\n",
      "         5.1392e-01,  3.3680e-01,  3.1416e-01,  4.6115e-02,  1.1959e-02,\n",
      "         2.1390e-02,  3.3534e-01,  3.3638e-01,  6.8808e-01,  5.4397e-01,\n",
      "         3.9567e-01,  2.7154e-01,  2.4202e-01,  4.5395e-02,  2.8397e-02,\n",
      "         2.9207e-02,  8.8490e-02, -1.0173e-01,  5.7741e-01,  7.7602e-01,\n",
      "         6.3512e-01,  4.8123e-01,  4.5156e-01,  2.9240e-02,  1.6413e-02,\n",
      "         2.9964e-01,  3.4877e-01, -3.5499e-02,  5.3757e-01,  7.9306e-01,\n",
      "         5.0109e-01,  3.7688e-01,  3.4665e-01,  2.6495e-02,  1.2102e-02,\n",
      "         2.2366e-01,  2.9297e-01, -7.0167e-02,  4.1580e-01,  1.8783e-01,\n",
      "         4.9784e-02, -2.6490e-02, -6.2631e-02, -1.2729e-01, -1.6491e-01,\n",
      "        -2.3300e-01, -2.8802e-01, -3.6004e-01]), tensor([ 6.9000e+02,  6.5367e+00,  4.2000e+01,  3.7377e+00,  6.0870e-02,\n",
      "        -2.7990e+00,  1.6429e+01,  2.7990e+00, -2.7784e+00,  1.8493e+01,\n",
      "         4.8629e+00,  5.4844e+00, -1.9914e+00,  3.4000e+02,  5.3920e+01,\n",
      "         9.6326e+01,  9.5317e-01,  1.1570e+00, -4.7184e-01,  7.8865e-12,\n",
      "        -2.5425e-01,  4.7912e-01,  4.2000e+01,  6.2500e-01,  3.7500e-01,\n",
      "         9.0533e-01,  9.4675e-02,  0.0000e+00,  1.8814e-01,  1.9812e-01,\n",
      "         5.3998e-01,  5.5082e-01,  7.0416e-01,  8.4306e-01,  8.5041e-01,\n",
      "         8.5511e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00,  9.3181e-01,\n",
      "         9.4285e-01,  9.7765e-01,  9.7322e-01,  9.7322e-01,  9.3235e-01,\n",
      "         5.9371e-01,  0.0000e+00,  8.4554e-01,  7.5930e-01,  8.4298e-01,\n",
      "         9.1998e-01,  9.2119e-01,  7.5894e-01,  5.8813e-01,  2.8656e-01,\n",
      "         1.0000e+00,  0.0000e+00,  3.3333e-01,  2.5000e-01,  4.0000e-01,\n",
      "         5.0000e-01,  5.7143e-01,  6.2500e-01,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.6667e-01,\n",
      "         7.5000e-01,  6.0000e-01,  5.0000e-01,  4.2857e-01,  3.7500e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.1989e-01,  2.1989e-01,  2.1989e-01,  1.0000e+00,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5452e-02,\n",
      "         8.5452e-02,  2.2869e-01,  2.2869e-01,  2.2869e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  1.9335e-02,  1.9335e-02,\n",
      "         2.7957e-01,  2.7957e-01,  8.9671e-01,  8.9671e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  4.7479e-02,  4.7479e-02,\n",
      "         2.9250e-01,  7.6260e-01,  7.6260e-01,  8.4877e-01,  8.4877e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  3.3845e-02,  3.1224e-01,\n",
      "         3.1224e-01,  8.6790e-01,  8.8364e-01,  8.8364e-01,  9.7087e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  4.0209e-02,  2.7803e-01,\n",
      "         7.8072e-01,  7.8470e-01,  7.8470e-01,  8.9084e-01,  9.8121e-01,\n",
      "         1.0000e+00,  3.6597e-01,  2.8570e-01,  4.3912e-01,  4.6102e-01,\n",
      "         5.2644e-01,  5.5404e-01,  4.2494e-01,  3.6814e-01,  4.2860e-01,\n",
      "         3.9606e-01,  4.1015e-01,  4.0084e-01,  9.0379e-01,  9.0643e-01,\n",
      "         9.0616e-01,  9.0588e-01,  9.0560e-01,  9.0533e-01,  9.6210e-02,\n",
      "         9.3567e-02,  9.3842e-02,  9.4118e-02,  9.4395e-02,  9.4675e-02,\n",
      "         0.0000e+00,  1.7549e-01,  2.6181e-01,  3.0667e-01,  3.7220e-01,\n",
      "         4.1430e-01,  5.2332e-01,  5.8068e-01,  6.6534e-01,  7.0240e-01,\n",
      "         0.0000e+00,  1.4001e-01,  2.1073e-01,  2.7230e-01,  3.1877e-01,\n",
      "         3.7984e-01,  4.5691e-01,  5.4666e-01,  6.0346e-01,  6.6408e-01,\n",
      "         0.0000e+00,  2.0564e-01,  3.3437e-01,  4.2444e-01,  4.8376e-01,\n",
      "         5.3338e-01,  5.9877e-01,  6.6063e-01,  7.0419e-01,  7.8616e-01,\n",
      "         0.0000e+00,  2.6068e-01,  3.8710e-01,  4.4633e-01,  5.1086e-01,\n",
      "         5.5858e-01,  6.2480e-01,  6.7529e-01,  7.4521e-01,  8.4785e-01,\n",
      "         0.0000e+00,  2.8393e-01,  4.1720e-01,  4.9537e-01,  5.3907e-01,\n",
      "         5.9669e-01,  6.4073e-01,  7.0480e-01,  7.7508e-01,  8.5840e-01,\n",
      "         0.0000e+00,  3.2565e-01,  4.6457e-01,  5.2254e-01,  5.6812e-01,\n",
      "         6.2039e-01,  6.6839e-01,  7.2898e-01,  8.0953e-01,  8.8038e-01,\n",
      "         4.0022e-01,  3.5928e-01,  4.7314e-01,  5.0567e-01,  5.3113e-01,\n",
      "         5.5886e-01,  2.1187e-01,  2.0150e-01,  2.2871e-01,  2.3528e-01,\n",
      "         2.3888e-01,  2.4247e-01,  7.4434e-01, -1.1176e-01, -3.7326e-01,\n",
      "        -2.8106e-01,  2.1173e-02,  1.4560e-01, -1.1254e-01, -1.1190e-01,\n",
      "        -3.5954e-01, -3.7860e-01, -2.2455e-01, -6.7114e-02, -3.2756e-01,\n",
      "        -2.6875e-01,  1.4800e-02,  1.4046e-01, -1.4259e-01, -1.4335e-01,\n",
      "        -3.1611e-01, -4.2246e-01, -2.2170e-01, -1.0499e-01, -2.8639e-01,\n",
      "        -1.9278e-01, -1.6231e-01,  2.4555e-01, -4.0950e-01, -4.1327e-01,\n",
      "        -2.7040e-01, -3.9431e-01, -1.3672e-01, -1.1605e-02, -1.1371e-01,\n",
      "        -5.0660e-02,  3.0404e-01,  6.5619e-01,  7.9860e-02,  7.8028e-02,\n",
      "         2.0578e-01,  9.2073e-02,  3.2566e-01, -2.6332e-02, -4.7171e-02,\n",
      "         1.7016e-02,  2.7308e-01,  6.1130e-01, -1.5488e-02,  4.9258e-02,\n",
      "         2.2391e-01,  1.1070e-01,  3.4943e-01,  6.7965e-02,  4.9816e-02,\n",
      "         7.2462e-02,  3.6567e-01,  6.6447e-01,  1.4349e-01,  2.3210e-01,\n",
      "         3.5689e-01,  2.4758e-01,  4.8030e-01,  3.4261e-01,  3.4261e-01,\n",
      "         1.0445e-01,  1.2272e-01, -6.5739e-01,  6.3218e-03,  6.3218e-03,\n",
      "        -1.9221e-02, -1.2192e-01,  0.0000e+00,  2.6272e-01,  2.6272e-01,\n",
      "         1.7727e-01,  3.4037e-02, -7.3728e-01, -6.4205e-02, -6.4205e-02,\n",
      "        -8.4259e-02, -1.5122e-01,  0.0000e+00,  2.9778e-01,  2.9778e-01,\n",
      "         2.8090e-01,  5.3685e-02, -5.7533e-01, -4.8515e-01, -4.8515e-01,\n",
      "        -4.9908e-01, -2.2080e-01,  0.0000e+00,  7.4231e-01,  7.4231e-01,\n",
      "         6.9931e-01,  4.7737e-01, -2.6487e-02,  5.1562e-02,  5.1562e-02,\n",
      "         3.6926e-02, -1.6347e-01,  0.0000e+00,  7.5687e-01,  7.5687e-01,\n",
      "         7.2785e-01,  4.8918e-01,  1.2795e-02, -6.9473e-04, -6.9473e-04,\n",
      "        -7.5479e-02, -1.0045e-01,  0.0000e+00,  9.0285e-01,  9.0285e-01,\n",
      "         8.6654e-01,  6.5183e-01,  1.9798e-01,  1.9438e-01,  1.9438e-01,\n",
      "         9.8555e-02,  1.6965e-02,  0.0000e+00,  1.7327e-01,  9.1729e-02,\n",
      "        -8.3717e-02, -1.3623e-01, -2.3388e-01, -3.4738e-01, -1.3881e-01,\n",
      "        -1.0759e-01, -1.6610e-01, -2.1032e-01,  1.5797e-01,  1.1454e-01,\n",
      "        -1.2148e-01, -1.6818e-01, -2.3014e-01, -3.9650e-01, -1.7265e-01,\n",
      "        -1.3990e-01, -1.9455e-01, -2.1243e-01,  2.7037e-01,  1.5025e-02,\n",
      "        -1.8489e-01, -2.4203e-01, -3.4167e-01, -3.7748e-01, -2.5852e-01,\n",
      "        -1.1892e-02, -2.7407e-01, -1.2902e-01,  6.8301e-01,  4.7087e-01,\n",
      "         2.4259e-01,  2.6528e-01,  1.7870e-01,  1.0912e-01,  1.6683e-01,\n",
      "         1.0770e-01,  6.6008e-02,  1.4271e-03,  7.1300e-01,  4.4997e-01,\n",
      "         2.4420e-01,  2.5298e-01,  1.6359e-01,  1.3189e-01,  1.7208e-01,\n",
      "         1.7976e-01,  1.3721e-02,  5.8965e-03,  8.4988e-01,  5.4223e-01,\n",
      "         4.1098e-01,  3.5621e-01,  3.1316e-01,  2.6378e-01,  2.1843e-01,\n",
      "         1.6119e-01,  8.5092e-02,  1.8150e-02]), tensor([ 6.9000e+02,  6.5367e+00,  4.2000e+01,  3.7377e+00,  6.0870e-02,\n",
      "        -2.7990e+00,  1.6429e+01,  2.7990e+00, -2.7784e+00,  1.8493e+01,\n",
      "         4.8629e+00,  5.4844e+00, -1.9914e+00,  3.4000e+02,  5.3920e+01,\n",
      "         9.6326e+01,  9.5317e-01,  1.1570e+00, -4.7184e-01,  7.5067e-22,\n",
      "        -2.5425e-01,  4.5775e-01,  4.2000e+01,  6.2500e-01,  3.7500e-01,\n",
      "         9.0828e-01,  9.1716e-02,  0.0000e+00,  2.7445e-03,  4.9241e-01,\n",
      "         6.2972e-01,  6.2995e-01,  6.3137e-01,  6.4194e-01,  7.6785e-01,\n",
      "         8.8062e-01,  1.0000e+00,  9.0486e-01,  9.0486e-01,  9.1518e-01,\n",
      "         9.2921e-01,  9.5859e-01,  8.6669e-01,  8.6669e-01,  1.0000e+00,\n",
      "         0.0000e+00,  7.0745e-01,  1.0000e+00,  7.3952e-01,  7.4088e-01,\n",
      "         9.3460e-01,  8.3936e-01,  7.5399e-01,  9.8445e-01,  0.0000e+00,\n",
      "         9.2454e-01,  8.3588e-01,  3.3333e-01,  2.5000e-01,  4.0000e-01,\n",
      "         5.0000e-01,  5.7143e-01,  6.2500e-01,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.6667e-01,\n",
      "         7.5000e-01,  6.0000e-01,  5.0000e-01,  4.2857e-01,  3.7500e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.1989e-01,  2.1989e-01,  2.1989e-01,  1.0000e+00,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.5452e-02,\n",
      "         8.5452e-02,  2.2869e-01,  2.2869e-01,  2.2869e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  1.9335e-02,  1.9335e-02,\n",
      "         2.7957e-01,  2.7957e-01,  8.9671e-01,  8.9671e-01,  1.0000e+00,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  4.7479e-02,  4.7479e-02,\n",
      "         2.9250e-01,  7.6260e-01,  7.6260e-01,  8.4877e-01,  8.4877e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  3.3845e-02,  3.1224e-01,\n",
      "         3.1224e-01,  8.6790e-01,  8.8364e-01,  8.8364e-01,  9.7087e-01,\n",
      "         1.0000e+00,  0.0000e+00,  0.0000e+00,  8.9020e-03,  2.6091e-01,\n",
      "         8.0121e-01,  8.3104e-01,  8.3104e-01,  8.8424e-01,  9.9420e-01,\n",
      "         1.0000e+00,  3.6597e-01,  2.8570e-01,  4.3912e-01,  4.6102e-01,\n",
      "         5.2644e-01,  5.6115e-01,  4.2494e-01,  3.6814e-01,  4.2860e-01,\n",
      "         3.9606e-01,  4.1015e-01,  4.1385e-01,  9.0671e-01,  9.0936e-01,\n",
      "         9.0909e-01,  9.0882e-01,  9.0855e-01,  9.0828e-01,  9.3294e-02,\n",
      "         9.0643e-02,  9.0909e-02,  9.1176e-02,  9.1445e-02,  9.1716e-02,\n",
      "         0.0000e+00,  1.7549e-01,  2.6181e-01,  3.0667e-01,  3.7220e-01,\n",
      "         4.1430e-01,  5.2332e-01,  5.8068e-01,  6.6534e-01,  7.0240e-01,\n",
      "         0.0000e+00,  1.4001e-01,  2.1073e-01,  2.7230e-01,  3.1877e-01,\n",
      "         3.7984e-01,  4.5691e-01,  5.4666e-01,  6.0346e-01,  6.6408e-01,\n",
      "         0.0000e+00,  2.0564e-01,  3.3437e-01,  4.2444e-01,  4.8376e-01,\n",
      "         5.3338e-01,  5.9877e-01,  6.6063e-01,  7.0419e-01,  7.8616e-01,\n",
      "         0.0000e+00,  2.6068e-01,  3.8710e-01,  4.4633e-01,  5.1086e-01,\n",
      "         5.5858e-01,  6.2480e-01,  6.7529e-01,  7.4521e-01,  8.4785e-01,\n",
      "         0.0000e+00,  2.8393e-01,  4.1720e-01,  4.9537e-01,  5.3907e-01,\n",
      "         5.9669e-01,  6.4073e-01,  7.0480e-01,  7.7508e-01,  8.5840e-01,\n",
      "         0.0000e+00,  3.1251e-01,  4.5955e-01,  5.1815e-01,  5.7984e-01,\n",
      "         6.2254e-01,  6.8297e-01,  7.3736e-01,  8.1705e-01,  9.0168e-01,\n",
      "         4.0022e-01,  3.5928e-01,  4.7314e-01,  5.0567e-01,  5.3113e-01,\n",
      "         5.6316e-01,  2.1187e-01,  2.0150e-01,  2.2871e-01,  2.3528e-01,\n",
      "         2.3888e-01,  2.4906e-01,  7.0771e-01, -2.0567e-01, -1.1347e-01,\n",
      "         5.5826e-02, -2.1101e-01, -1.9195e-01,  3.1319e-01,  1.8876e-01,\n",
      "        -5.6964e-02,  5.5690e-02,  5.5048e-02, -1.3337e-01, -7.4553e-02,\n",
      "         1.2708e-01, -2.2826e-01, -1.2191e-01,  3.3465e-01,  2.0899e-01,\n",
      "        -2.7512e-02,  5.0839e-02,  5.1599e-02, -2.0171e-01, -1.0810e-01,\n",
      "        -2.0310e-02, -3.0963e-01, -1.8572e-01,  3.3023e-01, -7.7632e-02,\n",
      "        -5.2037e-02, -3.2859e-01, -3.2482e-01, -1.4735e-01, -8.4299e-02,\n",
      "        -4.5243e-02,  5.8435e-02,  1.7214e-01,  6.2255e-01,  2.7041e-01,\n",
      "         2.9202e-01,  4.4390e-02,  4.6221e-02, -1.5381e-01, -8.9620e-02,\n",
      "        -1.3297e-01,  4.0644e-03,  1.1727e-01,  5.0467e-01,  1.6645e-01,\n",
      "         2.4279e-01, -5.7378e-02, -1.2212e-01, -2.1333e-02, -2.9730e-03,\n",
      "         4.4229e-02,  1.7476e-01,  2.7844e-01,  6.2468e-01,  3.2743e-01,\n",
      "         4.0489e-01,  1.9943e-01,  1.4021e-01,  5.1020e-01,  5.1020e-01,\n",
      "         2.7204e-01,  2.9031e-01,  1.7391e-01, -4.8980e-01, -4.8980e-01,\n",
      "         1.4837e-01,  0.0000e+00,  4.5673e-02,  4.5692e-01,  4.5692e-01,\n",
      "         3.7146e-01,  2.2823e-01,  1.2999e-01, -5.4308e-01, -5.4308e-01,\n",
      "         1.0993e-01,  0.0000e+00,  4.2971e-02,  3.8246e-01,  3.8246e-01,\n",
      "         3.6558e-01,  1.3836e-01, -4.0047e-01, -4.9065e-01, -4.9065e-01,\n",
      "        -4.1440e-01,  0.0000e+00, -1.3612e-01,  7.0868e-01,  7.0868e-01,\n",
      "         6.6567e-01,  4.4373e-01,  1.7924e-02, -6.0125e-02, -6.0125e-02,\n",
      "         3.2873e-03,  0.0000e+00, -1.9711e-01,  6.5023e-01,  6.5023e-01,\n",
      "         6.2122e-01,  3.8255e-01, -1.0733e-01, -9.3840e-02, -9.3840e-02,\n",
      "        -1.8211e-01,  0.0000e+00, -2.0709e-01,  8.4802e-01,  8.4802e-01,\n",
      "         8.4043e-01,  6.2548e-01,  1.6461e-01,  1.3917e-01,  1.3917e-01,\n",
      "         9.3794e-02,  0.0000e+00, -4.9480e-03,  3.7794e-01,  4.4806e-02,\n",
      "        -8.5739e-02,  9.3106e-02,  1.7866e-01, -7.0993e-02,  2.8612e-01,\n",
      "         1.1265e-01, -3.7716e-01, -1.2824e-01,  3.8754e-01,  4.1828e-02,\n",
      "        -5.1871e-02,  8.2810e-02,  1.3329e-01, -4.3776e-02,  2.1904e-01,\n",
      "         1.4813e-01, -4.5893e-01, -1.7693e-01,  3.7906e-01,  5.5799e-02,\n",
      "        -8.0997e-02, -7.9435e-02, -2.0072e-01, -6.3164e-02, -2.6182e-01,\n",
      "         2.0162e-01, -5.6849e-01, -6.0089e-01,  6.8063e-01,  3.9901e-01,\n",
      "         2.6441e-01,  2.2636e-01,  1.5540e-01,  2.8112e-01,  1.4228e-01,\n",
      "         1.9479e-01, -9.5548e-02, -1.2232e-01,  5.7818e-01,  3.5550e-01,\n",
      "         2.1419e-01,  7.2313e-02,  5.3220e-02,  1.5094e-01, -6.3772e-02,\n",
      "         1.2392e-01, -2.0849e-01, -2.6308e-01,  8.0084e-01,  5.1262e-01,\n",
      "         3.7700e-01,  3.2296e-01,  2.6606e-01,  2.2668e-01,  1.7094e-01,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1.2079e-01,  4.7284e-02, -3.0774e-02])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-1365cb53892c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mb2_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb1_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mb1_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb1_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mb2_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb2_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# ranking accuracy.\n",
    "net2 = nets[1]\n",
    "# print(net2)\n",
    "n_sample = metadata.shape[0]\n",
    "n_sample = 10\n",
    "X = metadata[0:12, 0:418]\n",
    "X_tensor = torch.from_numpy(X)\n",
    "X_tensor = X_tensor.float()\n",
    "print(X_tensor)\n",
    "y = metadata[:, 418]\n",
    "y = torch.from_numpy(y)\n",
    "# pair_X = [np.hstack((X[i,:],X[i+1,:])) for i in range(0, n_sample, 2)]\n",
    "b1_x = [X_tensor[i,:] for i in range(0,n_sample, 2)]\n",
    "b2_x = [X_tensor[i+1,:] for i in range(0,n_sample, 2)]\n",
    "print(b1_x)\n",
    "b1_x = torch.tensor(b1_x)\n",
    "b2_x = torch.tensor(b2_x)\n",
    "\n",
    "print(b1_x.size())\n",
    "print(b2_x.size())\n",
    "\n",
    "pair_y = [(y[i]-y[i+1]) for i in range(0, n_sample, 2)]\n",
    "print(pari_y.size())\n",
    "pair_y = np.array(pair_y)\n",
    "pair_y[np.where(pair_y>0)[0]] = 1\n",
    "pair_y[np.where(pair_y<=0)[0]] = 0\n",
    "out = net2(X_tensor)\n",
    "\n",
    "pred = out.detach().numpy()\n",
    "pred = pred[:,0]\n",
    "pred = [(pred[i]-pred[i+1]) for i in range(0, n_sample, 2)]\n",
    "pred = np.array(pred)\n",
    "pred[np.where(pred>0)[0]] = 1\n",
    "pred[np.where(pred<=0)[0]] = 0\n",
    "print(np.shape(pair_y))\n",
    "# pair_X_tensor = torch.from_numpy(pair_X)\n",
    "# pair_y_tensor = torch.from_numpy(pair_y)\n",
    "print(accuracy_score(pair_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_3hiddens(\n",
      "  (input_bn): BatchNorm1d(418, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (first_hidden): Linear(in_features=418, out_features=200, bias=True)\n",
      "  (first_bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (second_hidden): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (second_bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (third_hidden): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (third_bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "MyLoss()\n",
      "The current device is :  cuda\n",
      "Preparing the dataset....\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/generate_metadata/new_bigmetadata/australian/query_time/2australian30_big_metadata30.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8104a0f3288c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# testloader = MetaDataSet(metadata_dir, BATCH_SIZE, num_WORKERS, DATASET_SHUFFLE, TASK)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mmetadata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:/generate_metadata/new_bigmetadata/australian/query_time/2australian30_big_metadata30.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mmetadata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:/generate_metadata/new_bigmetadata/australian/query_time/4australian30_big_metadata30.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mmetadata3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:/generate_metadata/new_bigmetadata/australian/query_time/10australian30_big_metadata30.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/generate_metadata/new_bigmetadata/australian/query_time/2australian30_big_metadata30.npy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "\n",
    "from MyNet import Net, MetaDataSet, MyLoss, Net_3hiddens\n",
    "\n",
    "# hyper parameters\n",
    "BATCH_SIZE = 128\n",
    "EPOCH_SIZE = 2\n",
    "\n",
    "LR = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY =  0.0005\n",
    "\n",
    "DATASET_SHUFFLE = False\n",
    "num_WORKERS = 3\n",
    "\n",
    "TASK = 'regression'\n",
    "\n",
    "LAMBDA = 1\n",
    "XI = 0.0005\n",
    "\n",
    "\n",
    "save_path = './'\n",
    "metadata_dir = 'E:/metadata数据集/new_bigmetadata/australian/query_time/'\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# net = Net(n_feature=396, first_n_hidden=100, second_n_hidden=20, n_output=2)\n",
    "# net_bn = Net(n_feature=418, first_n_hidden=200, second_n_hidden=100, n_output=1, batch_normalization=True)\n",
    "# net_no_bn = Net(n_feature=418, first_n_hidden=200, second_n_hidden=100, n_output=1, batch_normalization=False)\n",
    "net = Net_3hiddens(n_feature=418, first_n_hidden=200, second_n_hidden=100, third_n_hidden=50, n_output=1, batch_normalization=True)\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "criterion = MyLoss(XI, LAMBDA)\n",
    "print(net)\n",
    "print(optimizer)\n",
    "print(criterion)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('The current device is : ', device)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "\n",
    "print('Preparing the dataset....')\n",
    "# trainloader = MetaDataSet(metadata_dir, BATCH_SIZE, num_WORKERS, DATASET_SHUFFLE, TASK)\n",
    "# testloader = MetaDataSet(metadata_dir, BATCH_SIZE, num_WORKERS, DATASET_SHUFFLE, TASK)\n",
    "\n",
    "metadata1 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/2australian30_big_metadata30.npy')\n",
    "metadata2 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/4australian30_big_metadata30.npy')\n",
    "metadata3 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/10australian30_big_metadata30.npy')\n",
    "metadata4 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/20australian30_big_metadata30.npy')\n",
    "metadata5 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/30australian30_big_metadata30.npy')\n",
    "metadata6 = np.load('D:/generate_metadata/new_bigmetadata/australian/query_time/48australian30_big_metadata30.npy')\n",
    "\n",
    "metadata = np.vstack((metadata1, metadata2, metadata3, metadata4, metadata5, metadata6))\n",
    "\n",
    "X = metadata[:, 0:418]\n",
    "y = metadata[:, 418]\n",
    "\n",
    "X_tensor = torch.from_numpy(X)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "X_tensor = X_tensor.float()\n",
    "y_tensor = y_tensor.float()\n",
    "\n",
    "troch_dataset = Data.TensorDataset(X_tensor, y_tensor)\n",
    "trainloader = Data.DataLoader(dataset=troch_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=DATASET_SHUFFLE,\n",
    "                        num_workers=num_WORKERS)\n",
    "\n",
    "test_X = metadata1[:, 0:418]\n",
    "test_y = metadata1[:, 418]\n",
    "\n",
    "test_X_tensor = torch.from_numpy(X)\n",
    "test_y_tensor = torch.from_numpy(y)\n",
    "test_X_tensor = X_tensor.float()\n",
    "test_y_tensor = y_tensor.float()\n",
    "\n",
    "test_troch_dataset = Data.TensorDataset(X_tensor, y_tensor)\n",
    "testloader = Data.DataLoader(dataset=test_troch_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=DATASET_SHUFFLE,\n",
    "                        num_workers=num_WORKERS)\n",
    "\n",
    "print(\"Dataset is ready!\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "[1,  1000] ,progress 0.7891, mean loss: 0.0020050095\n",
      "Saving..\n",
      "Current mean_rank_acc: 1.0000000000\n",
      "Current mean r2 score: -3.6074960414\n",
      "\n",
      "Epoch: 2\n",
      "[2,  1000] ,progress 0.7891, mean loss: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0efca3ff9985>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-0efca3ff9985>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mr2score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mpair_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmin_b\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmin_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mpair_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair_pred\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m    533\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 534\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    535\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % (epoch+1))\n",
    "    net.train()\n",
    "    # \n",
    "    if epoch < EPOCH_SIZE * 0.3:\n",
    "        lam = 0\n",
    "        xi = 0.0005\n",
    "    elif epoch < EPOCH_SIZE * 0.6:\n",
    "        lam = 0.5\n",
    "        xi = 0.0005\n",
    "    else:\n",
    "        lam = 1\n",
    "        xi = 0.0001       \n",
    "    running_loss = 0.0\n",
    "    for step, (batch_x, batch_y) in enumerate(trainloader):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "#         min_b = int(BATCH_SIZE/2)\n",
    "        min_b = int(batch_y.size()[0]/2)\n",
    "\n",
    "        pari_y = batch_y[0:min_b] - batch_y[min_b:]\n",
    "        optimizer.zero_grad()\n",
    "        output1 = net(batch_x[0:min_b,:])\n",
    "        output2 = net(batch_x[min_b:,:])\n",
    "        loss = criterion(output1, output2, pari_y, batch_y, xi, lam)\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "  \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # print every 1000 mini-batches\n",
    "        if step % 1000 == 999:    \n",
    "            print('[%d, %5d] ,progress %.4f, mean loss: %.10f' %\n",
    "                (epoch + 1, step + 1, step/len(trainloader), running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    r2scorelist = []\n",
    "    acclist = []\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_y) in enumerate(testloader):\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "    #         min_b = int(BATCH_SIZE/2)\n",
    "            min_b = int(batch_y.size()[0]/2)\n",
    "            pari_y = batch_y[0:min_b] - batch_y[min_b:]\n",
    "            pari_y[np.where(pari_y>0)[0]] = 1\n",
    "            pari_y[np.where(pari_y<=0)[0]] = 1\n",
    "            output = net(batch_x)\n",
    "            pred = output.detach().numpy()\n",
    "            y = batch_y.detach().numpy()\n",
    "            r2score = r2_score(pred, y)\n",
    "            pair_pred = pred[0:min_b] - pred[min_b:]\n",
    "            pair_pred[np.where(pair_pred>0)[0]] = 1\n",
    "            pair_pred[np.where(pair_pred<=0)[0]] = 1\n",
    "            acc = accuracy_score(pair_pred, pari_y)\n",
    "            r2scorelist.append(r2score)\n",
    "            acclist.append(acc)\n",
    "\n",
    "    mean_acc = np.mean(acclist)\n",
    "    mean_r2 = np.mean(r2scorelist)\n",
    "    # Save checkpoint.\n",
    "    if mean_acc > best_acc:\n",
    "        print('Saving..')\n",
    "        print('Current mean_rank_acc: %.10f'%mean_acc)\n",
    "        print('Current mean r2 score: %.10f'%mean_r2)\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'mean_rank_acc': mean_acc,\n",
    "            'mean_r2_score':mean_r2,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = mean_acc\n",
    "        \n",
    "for epoch in range(4):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
